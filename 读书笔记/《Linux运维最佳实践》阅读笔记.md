### 第1章 深入理解DNS原理与部署BIND

DNS：Domain Name System，负责将域名转换到IP地址，反查IP到域名，宣告邮件路由等信息。

BIND：Berkeley Internet Name Domain，Linux、UNIX上部署的域名服务器。

#### 最佳实践1：禁用权威域名服务器递归查询

DNS组成部分：域名服务器（Name Server）即服务端；解析器（Resolver）即客户端

DNS域名服务器分类：

- 权威域名服务器：负责“授权域”下的域名解析服务，由上级权威域名服务器使用NS记录进行授权。
  - 根域名服务器：共13组，从a到m.root-servers.net。负责顶级域名的向下授权，返回顶级域名服务器的NS。
  - 顶级域名服务器：负责二级域名的向下授权或一级域名的解析，返回二级域名服务器的NS或直接返回一级域名的IP。根据一级域名分为通用顶级域名和国家代码顶级域名。
  - 二级域名服务器：负责三级域名的向下授权或二级域名的解析。
- 缓存域名服务器：接收解析器的请求，并向权威域名服务器获取解析记录，返回给解析器的同时，自己缓存一份，缓存时间为TTL。如8.8.8.8、114.114.114.114，或公司内部DNS服务器。
- 转发域名服务器：接收解析器的请求，转发给权威域名服务器获取解析记录，返回给解析器，不缓存结果。

DNS递归查询：域名解析器接收解析器的请求后，自己充当解析器，继续请求下一级域名服务器。

DNS迭代查询：域名解析器接收解析器的请求后，返回下一级域名服务器NS列表，由解析器再次访问。

递归和迭代查询是域名解析器的一个配置项，区别在于接收请求后自身是否需要代替其继续查询。递归查询将对自身性能造成比较大的影响。对于权威域名解析器来说，为保证域名解析功能正常，不可开启递归查询。

#### 最佳实践2：构建域名解析缓存

本地采用/etc/resolv.conf指定本地DNS服务器IP。

本节文章目的是在本机安装NSCD，以实现在本机对域名解析记录缓存，从而提高DNS响应速度，减少DNS对外部网络的依赖。但其实大部分本地DNS服务器都采用缓存域名服务器方式进行域名解析，所以无需在本机安装NSCD。

#### 最佳实践3：配置chroot加固BIND

chroot：程序执行chroot后，其后执行被限定到了chroot后的目录下，提供了一种安全约束机制。如果BIND被入侵，那么黑客拿到的权限被限制在指定目录下，不会外溢到其他系统目录中。

操作方式：创建受限用户、受限目录、修改用户对目录权限，将named所需文件拷贝到受限目录中，以受限用户和受限目录启动named进程即可。

#### 最佳实践4：利用BIND实现简单的负载均衡

BIND支持对同一个域名指定多个A记录和NS记录。

如果同一个域名指定了多个A记录，解析器发送多次请求中，BIND会轮询返回不同的IP，从而实现简单的负载均衡。

#### 最佳实践5：详情BIND视图技术及优化

​	BIND视图技术，可以对同一个资源记录根据DNS请求来源IP不同分配给解析器不同的解析结果，从而实现就近访问的效果，提高用户访问质量。

​	使用方式：创建acl/SD_CTC列举需要匹配的来源IP，使用view/SD_CTC来调用acl/SD_CTC。acl/SD_CTC的IP地址可通过：a、纯真IP数据库分支；b、BIND自带log分析 获取。

​	总结起来就是使用acl命令圈定一批来源ip，使用view的match-clients匹配该acl，废弃分配zone文件用于解析，使用named.conf加载acl和view使其生效。其中来源IP地址不是终端IP，而是终端本地DNS服务器IP。

#### 最佳实践6：关注BIND的漏洞信息

为保障BIND安全，关注BIND官网安全，并持续更新版本。（这TM都能作为最佳实践，服了）

#### 最佳实践7：掌握BIND监控技巧

监控关注3个方面：系统负载监控（cpu、内存、网络）；named进程监控；named服务监控（通过dig模拟用户请求，检查服务是否正常）

### 第2章 全面解析CDN技术与实战

CDN：Content Delivery Network，负责对站点静态内容（图片、视频、音频、文件等）代理、响应、缓存，提高用户访问质量。

#### 最佳实践8：架构典型CDN系统

采用DNS视图技术，就近访问CDN节点。

CDN节点功能：采用缓存和代理技术提高响应效率。对静态资源请求，先查询本地未过期的缓存，优先返回。如果没有对应资源，以代理的方式请求源站获取内容再返回给用户，并在本地缓存起来，CDN的代理请求到源站也可以优化跨运营商的高延迟。

CDN节点架构示例：采用LVS双节点 + Nginx集群 + Squid集群分3层结构。LVS负责4层网络负载均衡，Nginx负责反向代理，Squid负责缓存。

#### 最佳实践9：理解HTTP协议中的缓存控制：服务器缓存控制头部信息

客户端对静态文件发起HTTP请求，在响应内容中可包含如下信息，利用这些信息可减少客户端和服务端的交互：

- Last-Modified：文件最后修改时间。客户端下次可在请求的header带上“If-Modified-Since:该时间”，如文件未修改过，则服务端只返回304 Not Modified，节省带宽和时间。
- ETag：文件资源ID标签（由最后修改时间戳和文件大小计算而来）。客户端下次可在请求的header带上“If-None-Match:该值”，文件如无变化，也会返回304。
- Expires：文件过期时间。该时间之前客户端不会发起HTTP请求到服务端，而是直接使用本地缓存的文件。
- Cache-Control：max-age：客户端可缓存该文件的最大时间（秒）。该时间之前客户端直接使用本地缓存的文件。

#### 最佳实践10:配置和优化Squid

- 建议使用大内存服务器：对于热点文件，Squid使用内存进行缓存，大内存可避免热点文件从磁盘读取。
- 建议每个磁盘独立使用：大文件或冷文件，Squid使用磁盘缓存，磁盘独立使用可提高iops。
- 禁用atime更新：读取磁盘缓存不会更新inode访问时间。
- 配置Squid多实例：Squid是单进程运行，多CPU主机应部署多个Squid实例，各Squid实例配置信息隔离。
- 使用URL哈希对Squid多实例进行调度：对URL哈希，使相同URL访问同一Squid实例，提高缓存命中率，避免各Squid缓存内容重复
- 禁用缓存间通信协议：建议Squid各实例独立，不做通信。如果建立Squid集群，会导致缓存响应延时，也不利于问题排查。
- 架构二级缓存：实践中，会增加二级缓存节点，一级缓存是最边缘节点，近客户端，一级缓存将二级缓存当做源站。
- Squid Manager：管控服务，查询Squid运行状态和配置信息
- HTTP Range：允许客户端只获取静态文件部分内容的能力，如断点续传。使用方式：请求增加Range:bytes=1025-2048，表示客户端读取文件的1025到2048字节的内容。在Squid中可配置该值，以多线程分别获取同一文件的部分内容，提高下载速度。

#### 最佳实践11：优化缓存防盗链

盗链：本站资源被第三方网站直接在页面上引用。盗链既浪费本站带宽，又失去了版权文件控制。

防盗链方法：

- 使用HTTP Referer：Referer标明请求来自哪个页面调用的，如非本站页面，可拒绝访问。
- 使用生成动态链接：页面上动态产生资源URL，key包含baseurl + 时间 + 密钥的MD5值，CDN接收到请求对URL中的key进行验证。用于视频、音频等大文件。

#### 最佳实践12：实践视频点播CDN

本小节以Lighttpd + Nginx + Python + Perl，基于CDN架构实现一个视频点播逻辑。

架构上划分为：转发服务器、缓存服务器、同步源站服务器、源站服务器。并对每个服务器的用途、部署组件、工作原理做了粗浅的描述。**具体见书本内容**。

- 转发服务器：负责接收请求，根据URL结合本地数据库做流量分发。部署Nginx组件。提供URL校验、转发、缓存服务器节点检查、
- 缓存服务器：响应缓存内容，支持视频拖动。部署Lighttpd。
- 同步源站服务器：所有视频文件的下载（不知道和源站服务器有啥区别）。部署Lighttpd
- 源站服务器：所有视频文件的下载。部署Lighttpd。

#### 最佳实践13：设计大规模下载调度系统

**没啥太大参考价值**

特点：文件大（游戏客户端）、下载时间集中并发高

设计：客户端发送请求根据请求域名，转发到外部CDN服务器下载。

### 第3章 负载均衡和高可用

本章根据ISO 7层互联模型，从下至上介绍每个层级的负载均衡的基本常识

#### 最佳实践14：数据链路层负载均衡

数据链路层的数据块为“帧”(Frame)

数据链路层常见的物理设备是网卡、网桥。如果单网卡故障或想要分流到服务器的多张网卡，数据链路层的负载均衡可解决上述场景。

数据链路层负载均衡采用双网卡绑定(Bonding)，效果都是将两块或更多的网卡当做一块网卡使用，在增加带宽的同时也可以提高冗余性。例如可以将eth0和eth1物理网卡绑定成虚拟网卡bond0，bond0对外提供一个ip。单独拔掉eth0或eth1上的网线，网络连通性也不受影响，而且可支持流量大小接近eth0+eth1的总和

具体配置可以在网上查找：[linux系统双网卡绑定单个IP地址及网桥](https://blog.csdn.net/taiyang1987912/article/details/46550857)

#### 最佳实践15：4层负载均衡

4层负载均衡通过对TCP或UDP的Header信息判断转发到哪个RealServer处理。例如识别源端口或目标端口做转发。一般可用LVS支持。

4层负载均衡特点有：

- 模型简单，不关心上层业务，只做负载调度、转发、探活；
- 吞吐量大
- 应用范围广，几乎支持所有负载均衡，包括HTTP、数据库等；

#### 最佳实践16：7层负载均衡

7层负载均衡通过对协议（如HTTP）Header信息判断转发到哪个RealServer处理。例如识别HTTP请求方法、uri、host等做转发。一般可用Nginx支持。

7层负载均衡特点有：

- 模型复杂，细化到业务逻辑层面，支持uri等作为调度依据。
- 吞度量小
- 可精细化控制转发判断

#### 最佳实践17：基于DNS负载均衡

在DNS域名中配置多个A记录，按轮询或权重返回服务器ip。

基于DNS负载均衡特点：

- 配置简单
- 存在缓存问题，无法快速做故障切换
- 无探活，一般要配置其他负载方案和监控机制

#### 最佳实践18：基于重定向的负载均衡

基于重定向的负载均衡，是指客户端请求到负载均衡器，负载均衡器根据算法向客户端返回某一RealServer信息（ip、端口等），客户端直接向RealServer发起请求。整个流程同基于DNS负载均衡类似，特点也类似。同一般负载均衡的区别在于，基于重定向的负载均衡器不再担当流量传输的主路，而是作为“名称服务中心”的旁路存在。一般可用Nginx支持。

#### 最佳实践19：基于客户端的负载均衡

基于客户端的负载均衡，是指由客户端计算应该请求的RealServer，然后发起请求。典型的例子是Dubbo和Hsf等RPC框架，数据库读写分离。

基于客户端的负载均衡特点：

- 自己实现负载、探活等功能，无需额外负载均衡软硬件投入

#### 最佳实践20：高可用技术推荐

对于4层、7层、基于DNS、基于重定向的这4种负载均衡，都存在软硬件的单点故障问题，如何保证负载均衡软硬件的高可用呢？

常见的3种高可用协议：热备路由协议HSRP、虚拟路由冗余协议VRRP、共用地址冗余协议CARP。HSRP是思科的私有协议，VRRP是基于HSRP的开源协议并有增强，CARP是基于BSD系统的协议，Linux支持。

Linux常用的高可用软件：Heartbeat和Keepalived。一般Linux上采用VRRP协议的Keepalived进行高可用架构

### 第4章 配置及调优LVS
